version: '3'

vars:
  DC1_DIR: clusters/dc1/terraform
  DC2_DIR: clusters/dc2/terraform
  GKE_DIR: clusters/gke-europe-west1/terraform
  GKE_MANIFESTS_DIR: clusters/gke-europe-west1/manifests

tasks:
  # === Image Building ===

  build-images:
    desc: "Build HashiStack images with Packer"
    dir: "packer/gcp"
    cmds:
      - echo "Building HashiStack images for new project..."
      - packer build .
      - echo "HashiStack images built successfully"

  # === Infrastructure Deployment ===
  
  deploy-dc1:
    desc: "Deploy DC1 cluster (europe-southwest1)"
    dir: "{{.DC1_DIR}}"
    cmds:
      - terraform init
      - terraform apply -auto-approve
      - echo "=== DC1 Cluster Info ==="
      - terraform output cluster_info
      - echo "=== DC1 URLs ==="
      - terraform output hashistack_urls
      - echo "=== DC1 Environment Setup ==="
      - terraform output -json environment_setup | jq -r .bash_export

  deploy-dc2:
    desc: "Deploy DC2 cluster (europe-west1)"
    dir: "{{.DC2_DIR}}"
    cmds:
      - terraform init
      - terraform apply -auto-approve
      - echo "=== DC2 Cluster Info ==="
      - terraform output cluster_info
      - echo "=== DC2 URLs ==="
      - terraform output hashistack_urls
      - echo "=== DC2 Environment Setup ==="
      - terraform output -json environment_setup | jq -r .bash_export

  deploy-gke:
    desc: "Deploy GKE cluster (europe-west1)"
    dir: "{{.GKE_DIR}}"
    cmds:
      - terraform init
      - terraform apply -auto-approve
      - echo "=== GKE Cluster Info ==="
      - terraform output cluster_info
      - echo "=== GKE Auth Command ==="
      - terraform output gke_auth_command
      - echo "=== kubectl Commands ==="
      - terraform output kubectl_commands

  deploy-both:
    desc: "Deploy both DC1 and DC2 clusters (sequential)"
    cmds:
      - task: deploy-dc1
      - task: deploy-dc2
      - echo "=== Both clusters deployed ==="
      - echo "CRITICAL NEXT STEPS:"
      - echo "1. Run 'nomad setup consul -y' on each cluster's server nodes"
      - echo "2. Use task ssh-dc1-server and task ssh-dc2-server to connect"
      - echo "3. Then deploy networking and monitoring"

  deploy-all:
    desc: "Deploy DC1, DC2, and GKE clusters"
    cmds:
      - task: deploy-both
      - task: deploy-gke
      - echo "=== All clusters deployed ==="

  # === Consul-Nomad Integration Setup ===

  setup-consul-nomad-dc1:
    desc: "Setup Consul-Nomad integration for DC1"
    dir: "{{.DC1_DIR}}"
    cmds:
      - echo "Setting up Consul-Nomad integration for DC1..."
      - |
        SERVER_IP=$(terraform output -json server_nodes | jq -r '.hashi_servers."server-1".public_ip')
        ssh ubuntu@$SERVER_IP 'sudo nomad setup consul -y'
      - echo "DC1 Consul-Nomad integration complete"

  setup-consul-nomad-dc2:
    desc: "Setup Consul-Nomad integration for DC2"
    dir: "{{.DC2_DIR}}"
    cmds:
      - echo "Setting up Consul-Nomad integration for DC2..."
      - |
        SERVER_IP=$(terraform output -json server_nodes | jq -r '.hashi_servers."server-1".public_ip')
        ssh ubuntu@$SERVER_IP 'sudo nomad setup consul -y'
      - echo "DC2 Consul-Nomad integration complete"

  setup-consul-nomad-both:
    desc: "Setup Consul-Nomad integration for both clusters"
    cmds:
      - task: setup-consul-nomad-dc1
      - task: setup-consul-nomad-dc2
      - echo "=== Consul-Nomad integration complete for both clusters ==="

  # === Application Deployment ===

  deploy-traefik-dc1:
    desc: "Deploy Traefik to DC1"
    dir: "clusters/dc1"
    vars:
      NOMAD_ADDR:
        sh: cd terraform && terraform output -json hashistack_urls | jq -r '.nomad.api'
      NOMAD_TOKEN:
        sh: cd terraform && terraform output -json auth_tokens | jq -r '.nomad_token'
    cmds:
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/monitoring/traefik.hcl
      - echo "Traefik deployed to DC1"
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job status traefik

  deploy-traefik-dc2:
    desc: "Deploy Traefik to DC2"
    dir: "clusters/dc2"
    vars:
      NOMAD_ADDR:
        sh: cd terraform && terraform output -json hashistack_urls | jq -r '.nomad.api'
      NOMAD_TOKEN:
        sh: cd terraform && terraform output -json auth_tokens | jq -r '.nomad_token'
    cmds:
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/monitoring/traefik.hcl
      - echo "Traefik deployed to DC2"
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job status traefik

  deploy-traefik:
    desc: "Deploy Traefik to both clusters"
    cmds:
      - task: deploy-traefik-dc1
      - task: deploy-traefik-dc2
      - echo "=== Traefik deployed to both clusters ==="

  deploy-monitoring-dc1:
    desc: "Deploy Prometheus, Grafana, and Loki to DC1"
    dir: "clusters/dc1"
    vars:
      NOMAD_ADDR:
        sh: cd terraform && terraform output -json hashistack_urls | jq -r '.nomad.api'
      NOMAD_TOKEN:
        sh: cd terraform && terraform output -json auth_tokens | jq -r '.nomad_token'
      CONSUL_HTTP_ADDR:
        sh: cd terraform && terraform output -json hashistack_urls | jq -r '.consul.api'
      CONSUL_HTTP_TOKEN:
        sh: cd terraform && terraform output -json auth_tokens | jq -r '.consul_token'
    cmds:
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/monitoring/loki.hcl
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/monitoring/prometheus.hcl
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/monitoring/grafana.hcl
      - export CONSUL_HTTP_ADDR="{{.CONSUL_HTTP_ADDR}}" && export CONSUL_HTTP_TOKEN="{{.CONSUL_HTTP_TOKEN}}" && consul config write ../consul/peering/configs/proxy-defaults-access-logs.hcl
      - echo "Monitoring stack with logging deployed to DC1"
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job status loki
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job status prometheus
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job status grafana

  deploy-monitoring-dc2:
    desc: "Deploy Prometheus, Grafana, and Loki to DC2"
    dir: "clusters/dc2"
    vars:
      NOMAD_ADDR:
        sh: cd terraform && terraform output -json hashistack_urls | jq -r '.nomad.api'
      NOMAD_TOKEN:
        sh: cd terraform && terraform output -json auth_tokens | jq -r '.nomad_token'
      CONSUL_HTTP_ADDR:
        sh: cd terraform && terraform output -json hashistack_urls | jq -r '.consul.api'
      CONSUL_HTTP_TOKEN:
        sh: cd terraform && terraform output -json auth_tokens | jq -r '.consul_token'
    cmds:
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/monitoring/loki.hcl
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/monitoring/prometheus.hcl
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/monitoring/grafana.hcl
      - export CONSUL_HTTP_ADDR="{{.CONSUL_HTTP_ADDR}}" && export CONSUL_HTTP_TOKEN="{{.CONSUL_HTTP_TOKEN}}" && consul config write ../consul/peering/configs/proxy-defaults-access-logs.hcl
      - echo "Monitoring stack with logging deployed to DC2"
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job status loki
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job status prometheus
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job status grafana

  deploy-monitoring:
    desc: "Deploy monitoring stack to both clusters"
    cmds:
      - task: deploy-monitoring-dc1
      - task: deploy-monitoring-dc2
      - echo "=== Monitoring stack deployed to both clusters ==="

  # === Status and Information ===

  check-infra:
    desc: "Check deployment status of both clusters"
    cmds:
      - echo "Checking DC1 Infrastructure..."
      - cd {{.DC1_DIR}} && terraform show > /dev/null 2>&1 && echo "DC1 deployed" || echo "DC1 not deployed"
      - echo "Checking DC2 Infrastructure..."  
      - cd {{.DC2_DIR}} && terraform show > /dev/null 2>&1 && echo "DC2 deployed" || echo "DC2 not deployed"

  status-dc1:
    desc: "Show DC1 status"
    dir: "{{.DC1_DIR}}"
    cmds:
      - terraform output cluster_info || echo "No cluster info available"

  status-dc2:
    desc: "Show DC2 status"
    dir: "{{.DC2_DIR}}"
    cmds:
      - terraform output cluster_info || echo "No cluster info available"

  status-gke:
    desc: "Show GKE status"
    dir: "{{.GKE_DIR}}"
    cmds:
      - terraform output cluster_info || echo "No GKE cluster info available"
      - echo "=== kubectl Authentication ==="
      - terraform output gke_auth_command || echo "No auth command available"

  # === GKE Consul Integration ===

  gke-auth:
    desc: "Authenticate kubectl with GKE cluster"
    dir: "{{.GKE_DIR}}"
    cmds:
      - terraform output -raw gke_auth_command | sh
      - kubectl cluster-info

  gke-setup-secrets:
    desc: "Setup Consul secrets for GKE (requires CONSUL_ENT_LICENSE)"
    dir: "{{.GKE_MANIFESTS_DIR}}"
    cmds:
      - kubectl create namespace consul --dry-run=client -o yaml | kubectl apply -f -
      - ./setup-secrets-auto.sh

  gke-deploy-consul:
    desc: "Deploy Consul to GKE cluster"
    dir: "{{.GKE_MANIFESTS_DIR}}"
    cmds:
      - helm repo add hashicorp https://helm.releases.hashicorp.com
      - helm repo update
      - helm install consul hashicorp/consul --namespace consul --values gke-consul-values.yaml

  gke-status-consul:
    desc: "Check Consul status in GKE"
    cmds:
      - echo "=== Consul Pods ==="
      - kubectl get pods -n consul
      - echo ""
      - echo "=== Consul Services ==="
      - kubectl get svc -n consul
      - echo ""
      - echo "=== Recent Logs ==="
      - kubectl logs -n consul -l app=consul --tail=10

  gke-cleanup-consul:
    desc: "Remove Consul from GKE"
    cmds:
      - helm uninstall consul -n consul || echo "Consul not installed"
      - kubectl delete namespace consul || echo "Namespace not found"

  show-urls:
    desc: "Show all access URLs for both clusters"
    cmds:
      - echo "=== DC1 URLs ==="
      - cd {{.DC1_DIR}} && terraform output hashistack_urls || echo "No URLs available"
      - cd {{.DC1_DIR}} && terraform output monitoring_urls || echo "No monitoring URLs available"
      - cd {{.DC1_DIR}} && echo "app-ui = http://$(terraform output -json load_balancers | jq -r '.clients_lb.ip'):8081" || echo "No app-ui URL available"
      - echo ""
      - echo "=== DC2 URLs ==="
      - cd {{.DC2_DIR}} && terraform output hashistack_urls || echo "No URLs available"
      - cd {{.DC2_DIR}} && terraform output monitoring_urls || echo "No monitoring URLs available"
      - cd {{.DC2_DIR}} && echo "app-ui = http://$(terraform output -json load_balancers | jq -r '.clients_lb.ip'):8081" || echo "No app-ui URL available"

  eval-vars-dc1:
    desc: "Show environment variables for DC1"
    dir: "{{.DC1_DIR}}"
    cmds:
      - echo "# DC1 Environment Setup"
      - terraform output -json environment_setup | jq -r .bash_export

  eval-vars-dc2:
    desc: "Show environment variables for DC2"
    dir: "{{.DC2_DIR}}"
    cmds:
      - echo "# DC2 Environment Setup"
      - terraform output -json environment_setup | jq -r .bash_export

  eval-vars:
    desc: "Show environment variables for both clusters"
    cmds:
      - task: eval-vars-dc1
      - echo ""
      - task: eval-vars-dc2

  get-server-ips-dc1:
    desc: "Get external server IPs for DC1 (for Kubernetes integration)"
    dir: "{{.DC1_DIR}}"
    cmds:
      - echo "=== DC1 Server External IPs ==="
      - gcloud compute instances list --filter='name~hashi-server' --format='value(name,EXTERNAL_IP)' | head -3
      - echo ""
      - echo "For Kubernetes Helm values, use these IPs in externalServers.hosts:"
      - gcloud compute instances list --filter='name~hashi-server' --format='value(EXTERNAL_IP)' | head -3 | sed 's/^/  - "/' | sed 's/$/"/'

  get-server-ips-dc2:
    desc: "Get external server IPs for DC2 (for Kubernetes integration)"
    dir: "{{.DC2_DIR}}"
    cmds:
      - echo "=== DC2 Server External IPs ==="
      - gcloud compute instances list --filter='name~hashi-server' --format='value(name,EXTERNAL_IP)' | head -3
      - echo ""
      - echo "For Kubernetes Helm values, use these IPs in externalServers.hosts:"
      - gcloud compute instances list --filter='name~hashi-server' --format='value(EXTERNAL_IP)' | head -3 | sed 's/^/  - "/' | sed 's/$/"/'

  get-server-ips:
    desc: "Get external server IPs for both clusters"
    cmds:
      - task: get-server-ips-dc1
      - echo ""
      - task: get-server-ips-dc2


  # === Demo Applications ===

  deploy-demo-apps-dc1:
    desc: "Deploy demo applications to DC1"
    dir: "clusters/dc1"
    vars:
      NOMAD_ADDR:
        sh: cd terraform && terraform output -json hashistack_urls | jq -r '.nomad.api'
      NOMAD_TOKEN:
        sh: cd terraform && terraform output -json auth_tokens | jq -r '.nomad_token'
    cmds:
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/demo-fake-service/frontend.nomad.hcl
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/demo-fake-service/backend.nomad.hcl
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/api-gw.nomad.hcl
      - echo "Demo applications deployed to DC1"

  deploy-demo-apps-dc2:
    desc: "Deploy demo applications to DC2"
    dir: "clusters/dc2"
    vars:
      NOMAD_ADDR:
        sh: cd terraform && terraform output -json hashistack_urls | jq -r '.nomad.api'
      NOMAD_TOKEN:
        sh: cd terraform && terraform output -json auth_tokens | jq -r '.nomad_token'
    cmds:
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/demo-fake-service/frontend.nomad.hcl
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/demo-fake-service/backend.nomad.hcl
      - export NOMAD_ADDR="{{.NOMAD_ADDR}}" && export NOMAD_TOKEN="{{.NOMAD_TOKEN}}" && nomad job run jobs/api-gw.nomad.hcl
      - echo "Demo applications deployed to DC2"

  deploy-demo-apps:
    desc: "Deploy demo applications to both clusters"
    cmds:
      - task: deploy-demo-apps-dc1
      - task: deploy-demo-apps-dc2
      - echo "=== Demo applications deployed to both clusters ==="

  # === Quick Access ===

  app-ui-dc1:
    desc: "Open DC1 frontend application in browser"
    dir: "{{.DC1_DIR}}"
    cmds:
      - |
        APP_URL="http://$(terraform output -json load_balancers | jq -r '.clients_lb.ip'):8081"
        echo "Opening DC1 app-ui at: $APP_URL"
        open "$APP_URL" || echo "Visit: $APP_URL"

  app-ui-dc2:
    desc: "Open DC2 frontend application in browser"
    dir: "{{.DC2_DIR}}"
    cmds:
      - |
        APP_URL="http://$(terraform output -json load_balancers | jq -r '.clients_lb.ip'):8081"
        echo "Opening DC2 app-ui at: $APP_URL"
        open "$APP_URL" || echo "Visit: $APP_URL"

  app-ui:
    desc: "Show both DC1 and DC2 app-ui URLs"
    cmds:
      - echo "=== Frontend Application URLs ==="
      - task: app-ui-dc1
      - task: app-ui-dc2

  ssh-dc1-server:
    desc: "SSH to DC1 server node"
    dir: "{{.DC1_DIR}}"
    cmds:
      - |
        SERVER_IP=$(terraform output -json server_nodes | jq -r '.hashi_servers."server-1".public_ip')
        echo "Connecting to DC1 server at $SERVER_IP"
        ssh ubuntu@$SERVER_IP

  ssh-dc2-server:
    desc: "SSH to DC2 server node"
    dir: "{{.DC2_DIR}}"
    cmds:
      - |
        SERVER_IP=$(terraform output -json server_nodes | jq -r '.hashi_servers."server-1".public_ip')
        echo "Connecting to DC2 server at $SERVER_IP"
        ssh ubuntu@$SERVER_IP

  # === Cleanup ===

  destroy-dc1:
    desc: "Destroy DC1 cluster"
    dir: "{{.DC1_DIR}}"
    cmds:
      - terraform destroy -auto-approve

  destroy-dc2:
    desc: "Destroy DC2 cluster"
    dir: "{{.DC2_DIR}}"
    cmds:
      - terraform destroy -auto-approve

  destroy-gke:
    desc: "Destroy GKE cluster"
    dir: "{{.GKE_DIR}}"
    cmds:
      - terraform destroy -auto-approve

  destroy-both:
    desc: "Destroy both clusters"
    cmds:
      - task: destroy-dc1
      - task: destroy-dc2

  destroy-all:
    desc: "Destroy all clusters (DC1, DC2, GKE)"
    cmds:
      - task: destroy-dc1
      - task: destroy-dc2
      - task: destroy-gke

  # === Cluster Peering ===

  peering:help:
    desc: "Show cluster peering setup instructions"
    silent: true
    cmds:
      - echo "Consul Cluster Peering Setup"
      - echo "Prerequisites - Both clusters must be deployed"
      - echo "task peering:env-setup - Get environment setup"
      - echo "task peering:setup - Start peering setup"
      - echo "task peering:establish - Establish peering connection"
      - echo "task peering:complete - Complete setup"
      - echo "task peering:verify - Verify peering works"
      - echo "Detailed guide at consul/peering/README.md"

  peering:env-setup:
    desc: "Show environment setup for cluster peering"
    silent: true
    cmds:
      - echo "Set environment variables for cluster peering"
      - echo "See consul/peering/README.md for detailed instructions"

  peering:setup:
    desc: "Start cluster peering setup (phases 1-8)"
    dir: consul/peering
    cmds:
      - task: setup-peering
    preconditions:
      - sh: "[ ! -z \"$DC1_CONSUL_ADDR\" ]"
        msg: "DC1_CONSUL_ADDR not set. Run 'task peering:env-setup' for instructions"
      - sh: "[ ! -z \"$DC2_CONSUL_ADDR\" ]"
        msg: "DC2_CONSUL_ADDR not set. Run 'task peering:env-setup' for instructions"

  peering:establish:
    desc: "Establish peering connection (run after setup)"
    dir: consul/peering
    cmds:
      - task: establish-peering

  peering:complete:
    desc: "Complete peering setup (phases 9-13)"
    dir: consul/peering
    cmds:
      - task: complete-peering

  peering:verify:
    desc: "Verify peering status and connectivity"
    dir: consul/peering
    cmds:
      - task: verify-setup
      - task: check-services

  peering:sameness-groups:
    desc: "Configure sameness groups for failover"
    dir: consul/peering
    cmds:
      - task: configure-sameness-groups

  peering:service-resolver:
    desc: "Configure service resolver for failover"
    dir: consul/peering
    cmds:
      - task: configure-service-resolver

  peering:cleanup:
    desc: "Clean up peering configuration"
    dir: consul/peering
    cmds:
      - task: cleanup-peering
      - task: cleanup-jobs

  # === Enhanced Status and Information ===

  status:
    desc: "Show status of both clusters and peering"
    cmds:
      - echo "=== Infrastructure Status ==="
      - task: check-infra
      - echo ""
      - echo "=== Cluster Access ==="
      - task: show-urls
      - echo ""
      - echo "=== Peering Status ==="
      - echo "Environment variables not set - run task peering env-setup"

  # === Help System ===

  help:
    desc: "Show all available tasks"
    silent: true
    cmds:
      - echo "HashiCorp Multi-Cluster Infrastructure"
      - echo "Use 'task --list' to see all available tasks"
      - echo "Main tasks - deploy-both, peering:help, status"

  default:
    cmds:
      - task: help